---
title: "Assignment 2"
author: "Wasi"
date: "2023-11-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


## Looking at the Study
$\textbf{Section 1: EDA and preprocessing etc}$

```{r}

df <- read.csv("myopia.csv", sep = ";", header = TRUE)
str(df)
df$GENDER <- factor(df$GENDER, levels = c(0,1), labels = c("male", "female"))
df$MYOPIC <- factor(df$MYOPIC, levels = c(0,1), labels = c("No", "Yes"))
df$MOMMY <- factor(df$MOMMY, levels = c(0,1), labels = c("No", "Yes"))
df$DADDY <- factor(df$DADMY, levels = c(0,1), labels = c("No", "Yes"))



proportion_myopic <- table(df$MYOPIC) / sum(!is.na(df$MYOPIC))

cat("Proportion of Myopic Children within first five years of follow up", proportion_myopic, "\n")


df$PARENTMY <- ifelse(df$MOMMY == "Yes" | df$DADMY == "Yes", 1, 0)
set.seed(19651)
n = nrow(df)

train <- sample(1:n, n*.6)
test <- setdiff(1:n, train)
train_data <- df[train, ]
test_data <- df[test, ]


```



$\textbf{Section 2:Logistic Regression}$

```{r}

logreg1 <- glm(MYOPIC ~ SPHEQ + AL + ACD, data = train_data, family = binomial)
logreg2 <- glm(MYOPIC ~ SPHEQ + AL + ACD + PARENTMY, data = train_data, family = binomial)
logreg3 <- glm(MYOPIC ~ SPHEQ + AL + ACD + PARENTMY + READHR + COMPHR + TVHR, data = train_data, family = binomial)
summary(logreg1)
summary(logreg2)
summary(logreg3)


print("In the summary output provided above , the p-value for the PARENTMY variable is 0.0141, which is less than 0.05 (assuming a one tailed 95% confidence interval). This indicates that the PARENTMY variable is statistically significant in predicting the response variable, and there is evidence to suggest that a parent's myopia status affects the child's likelihood of developing myopia.")

print("log reg2. It takes into account suitable number of parameters. Doesnt over or underfit")


predictions1 <- predict(logreg1, newdata = test_data, type = "response")
predictions2 <- predict(logreg2, newdata = test_data, type = "response")
predictions3 <- predict(logreg3, newdata = test_data, type = "response")


threshold <- 0.5


calculate_confusion_matrix <- function(predictions, threshold) {
  predicted_classes <- ifelse(predictions > threshold, "Yes", "No")
  actual_classes <- as.integer(test_data$MYOPIC)
  cm <- table(Actual = actual_classes, Predicted = predicted_classes)
  return(cm)
}

confusion_matrix1 <- calculate_confusion_matrix(predictions1, threshold)
confusion_matrix2 <- calculate_confusion_matrix(predictions2, threshold)
confusion_matrix3 <- calculate_confusion_matrix(predictions3, threshold)

# Q8
print("Confusion Matrix for logreg1:")
print(confusion_matrix1)

print("Confusion Matrix for logreg2:")
print(confusion_matrix2)

print("Confusion Matrix for logreg3:")
print(confusion_matrix3)

print("All three make the same number of false negatives. As a proportion of negatives, the solution would be logreg1,though!")

library(MLmetrics)
log_loss1 <- LogLoss(as.numeric(predictions1),as.numeric(test_data$MYOPIC))
cat("Log Loss for logreg1:", log_loss1, "\n")

log_loss2 <- LogLoss(as.numeric(predictions2),as.numeric(test_data$MYOPIC))


cat("Log Loss for logreg2:", log_loss2, "\n")

log_loss3 <- LogLoss(as.numeric(predictions3),as.numeric(test_data$MYOPIC))
cat("Log Loss for logreg1:", log_loss3, "\n")

# Since smaller is better. logreg1 is the best model according to  logloss metric.
print("Since smaller value is better. logreg1 is the best model according to  logloss metric.")

```


$\textbf{Section 3: LDA and QDA}$


```{r}


lda1 <- lda(MYOPIC ~ SPHEQ + AL + ACD, data = train_data)
lda2 <- lda(MYOPIC ~ SPHEQ + AL + ACD + PARENTMY, data = train_data)
lda3 <- lda(MYOPIC ~ SPHEQ + AL + ACD + PARENTMY + READHR + COMPHR + TVHR, data = train_data)
qda1 <- qda(MYOPIC ~ SPHEQ + AL + ACD, data = train_data)
qda2 <- qda(MYOPIC ~ SPHEQ + AL + ACD + PARENTMY, data = train_data)
qda3 <- qda(MYOPIC ~ SPHEQ + AL + ACD + PARENTMY + READHR + COMPHR + TVHR, data = train_data)

#lda1
table(testing_data$MYOPIC,predict(lda1,testing_data)$class)
#accuracy 
(220+2)/(220+26+2)

#lda2
table(testing_data$MYOPIC,predict(lda2,testing_data)$class)
#accuracy 
(224)/(248)

#lda3
table(testing_data$MYOPIC,predict(lda3,testing_data)$class)
#accuracy 
(221)/(248)

#qda1
table(testing_data$MYOPIC,predict(qda1,testing_data)$class)
#accuracy 
222/248

#qda2
table(testing_data$MYOPIC,predict(qda2,testing_data)$class)
#accuracy
220/248

#qda3
table(testing_data$MYOPIC,predict(qda3,testing_data)$class)
 
215/248


print("As it can be seen comparing our accuracy values,LDA2 has the highest accuracy!")

dis_score_lda2 <- predict(lda2,new_data=test_data, type = "scores")

best_score<-dis_score_lda2$x
summary(best_score)

```


$\textbf{Section 4: KNN}$


```{r}

library(caret)
library(class)

set.seed(3952538)

target_variable <- df$MYOPIC 


k_values <- c(2, 7, 13, 18, 23, 29, 34, 39, 45, 50)
predictors <- train_data[, c("SPHEQ", "AL", "ACD")]


k_values <- c(2, 7, 13, 18, 23, 29, 34, 39, 45, 50)

ctrl <- trainControl(method = "cv", number = 10)  
knn_model <- train(x = predictors, y = train_data$MYOPIC, method = "knn", tuneGrid = expand.grid(k = k_values), trControl = ctrl)

print(knn_model)

knn_18_model <- knn(train_data[, c("SPHEQ", "AL", "ACD")], test_data[, c("SPHEQ", "AL", "ACD")], train_data$MYOPIC, k = 18)

knn_predictions <- as.factor(knn_18_model)

test_error <- mean(knn_predictions != test_data$MYOPIC)



# Print the optimal k value
cat("Answer to Q8:Optimal value of k:", optimal_k, "\n")

# Build the k-NN model with k = 18
knn_18_model <- knn(train_data[, c("SPHEQ", "AL", "ACD")], test_data[, c("SPHEQ", "AL", "ACD")], train_data$MYOPIC, k = 18)

# Predict on the test data
knn_predictions <- as.factor(knn_18_model)


test_error <- mean(knn_predictions != test_data$MYOPIC)
cat("Test Error for k-NN model with k = 18:", test_error, "\n")

```
